# 一些训练的东西

## MSE & RMSE

MES ： 均方误差

  $MSE = \frac{1}{n} \sum^n_{i=1}(y_i-\hat{y}_i)^2$

RMSE： 均方根误差

  $RMSE = \sqrt{\frac{1}{n}\sum^n_{i=1}(y_i-\hat{y}_i)^2}$

均方误差通常用于回归问题，预测的是连续的数值，需要衡量预测值与其真实值之间的距离或者误差

对于分类问题来说，通常使用：

  * acc
  * precision：在所有被预测为正类的样本中，真正为正类的比例

    $Precision = \frac{TP}{TP+FP}$
    
  * recall:在所有真实为正类的样本中，被正确预测为正类的比例
    
      $Recall = \frac{TP}{TP+FN}$
    
  * f1分数：精确率和召回率的调和平均数
    
      $F1 = 2\cdot \frac{Precision \cdot Recall}{Precision + Recall}$
    
* 对数损失 LogLoss:衡量概率预测的不确定性

  $LogLoss = - 1\frac{1}{N}\sum^N_{i=1}[y_ilog(p_i)+(1-y_i)log(1-p_i)]$

* 交叉熵损失，预测概率分布与真实分布之间的差异，多分类问题公式：

    $CrossEntropy = -\sum^N_{i=1}\sum^M_{j=1}y_{ij}log(p_{ij})$
  
关于为什么对数损失和交叉熵损失使用负数：

  在信息伦中，当一个事件的概率为 $p$时，该事件包含的信息量定义为 $-log(p)$，概率越小，信息量越大，即罕见事件发生时提供的信息更多

  在机器学习中，我们希望通过最大化模型对正确标签的预测概率，即最大化对数似然： $最大化 log(p(正确类别))$

  最小化损失函数：但是由于优化算法通常设计为最小化目标函数，所以我们取负值，将最大化问题转换为最小化问题，$最小化:-log(p(正确类别))$

  梯度特性：负对数函数在概率接近1时梯度接近0，在概率接近0时梯度非常大
  
  * 当模型对正确类别非常自信( $p \approx 1$)时，损失很小，梯度也很小

  * 当模型对正确类别完全不自信( $p \approx 0$)时，损失无限大，梯度也很小
  
  *TP*：实际为正，预测为正
  
  *TN*：实际为负，预测为负
  
  *FP*：实际为负，预测为正
  
  *FN*：实际为正，预测为负

**为什么要使用最大似然估计**

在统计轮中，在一定条件下，最大似然估计量是一致的、渐近有效和渐近正态的，这意味着随着样本量增加，估计会收敛到真实参数值

1. 一致性： 意味着随着样本量 $n$趋于无穷大，估计值会概率收敛到真实参数值
2. 渐近有效：在所有无偏估计中，渐近有效的估计量达到克拉美-拉奥下界(方差的理论下限)；简单来说：在足够多的样本下，没有其他估计方法能比它更佳精确，具有更小的方差
3. 渐近正态：当样本足够大时，估计量的分布(参数模型的估计值)近似于正态分布；大样本下，估计误差遵循正态分布，使得可以构建置信区间和进行假设检验；参数的正态分布具有完整的理论支持，比如可以构建置信区间和进行假设检验，评估参数估计的不确定性；并且有很多明确的数学特性，可以使得我们更可靠地量化模型的不确定性，可以将复杂模型的数学分析更加简单

**为什么分类任务使用交叉熵而不是MSE**

1. 梯度消失问题： 当使用sigmoid或者softmax激活函数的时候，如果使用MSE，当预测值与真实值相差巨大会导致梯度变得很小，使得模型训练缓慢；但是交叉熵可以避免这个问题
2. 概率解释：在分类任务中，模型输出可以解释为个类别的概率分布，而交叉熵正好可以度量真实分布于预测分布之间的差异
3. 更快地收敛：对于分类来说，使用交叉熵收敛更好
4. 最大似然估计：

     从统计学角度来看，最小化交叉熵等价于最大化似然函数，这和分类问题的目标一样

     假设使用概率分布问题 $p(y|x)$来建模分类问题，其中 $x$是输入特征， $y$是类别标签，从统计学角度来看，我们希望找到模型参数 $\theta$使得观测数据的似然度最大：对数似然函数为：

     $log L(\theta) = \sum_i log p(y_i|x_i;\theta)$

   对于二分类问题，假设 $p(y=1|x;\theta) = \hat{y}$和 $p(y=0|x;\theta) = 1-\hat{y}$，那么对数似然可以写成：

     $log L(\theta) = \sum^n_{i=1}[y_ilog\hat{y}_i+(1-y_i)log(1-\hat{y}_i)]$

   最大化对数似然可以等价于最小化负对数似然：

     $-log L(\theta) = \sum^n_{i=1}[y_ilog\hat{y}_i-(1-y_i)log(1-\hat{y}_i)]$

   因此，对于多分类问题，可以类似推导为：

     $-log L(\theta) = \sum^n_{i=1}\sum^k_{j=1}-y_{ij}log\hat{y}_{ij}$

   从最大似然俩看，MSE相当于假设数据服从高斯分布的情况下的负对数似然，但是分类问题是离散的，可以使用概率分布，不符合高斯分布假设

6. 处理不平衡数据： 交叉熵在处理类别不平衡的数据集时通常比MSE更有效
7. 信息论： 从信息论来说，交叉上度量的是使用预测分布 $q$编码与真实分布 $p$所需的平均比特数，这和分类任务的本质高度一致

## reshape & view & permute & transpose

**视图操作**

在不复制底层数据的情况下，创建一个数据的新的表示方式，视图操作不会复制原始数据，而是创建一个指向相同内存位置的 **新引用**，原始数据和视图共享同一块内存

由于不复制数据，视图操作非常高效，几乎没有额外的内存开销

修改视图中的元素的同时会同时修改原始数据中的对应元素，可以做到数据同步

视图操作可以保证梯度的连续性，确保梯度能正确反向传播；并且可以自动处理不用形状之间的梯度映射

当通过视图操作创建一个新的视图之后，后续的操作实在这个视图上进行的：

1. 视图与原始数据之间的关系：

     视图和原始tensor共享底层数据；对视图的修改会反映到原始tensor上，反之亦然

     但是视图的形状信息是独立的

2. 链式操作的影响

   如果在视图上再执行修改形状的操作，得到的是视图的视图；这些操作可以形成一条视图链，所有视图都指向同一块原始内存

3. in-place的影响：

     一些就地操作可能会破坏视图关系：因为某些就地修改视图形状的操作可能导致内存重新分配，从而断开与原数据的联系；例如一些下划线结尾的操作： **add_(),mul_(),zero_()**,可以节省内存开销

与 **clone**之间的区别：clone会创建新的独立数据副本

视图的限制：

1. 连续性要求：张量必须是连续的，对于非连续张量需要先调用 **.contiguous**方法
2. 维度限制：视图操作不能改变数据的总元素数量；新的形状必须与原始元素数量兼容

1. reshape

     数据在哪从中的排列顺序不一定改变，只是重新解释数据的维度结构；

     **只要元素总数保持一致，可以将tensor变成任何形状**

     大部分是 **视图操作**，但是会尽量避免复制，但是不保证，当输入不连续时，会创建**副本**，再创建视图

2. view

     类似于reshape，但是更加严格

     是一个浅操作，不会复制数据，只是创建一个新的视图；如果原始tensor改变，view也会改变(共享底层存储)

     必须使用contiguous才可以，即tensor连续；纯粹的视图操作，保证不复制数据

     **关于什么是浅操作**

     不复制底层数据，只是创建新的引用；操作速度快，通常为 O(1)的时间复杂度

      常见的浅操作：

         1. view / reshape(当不需要复制的时候)

         2. 切片操作

         3. 转置

         4. unsqueeze/squeeze ： 添加或移除维度

3. permute

     视图操作，但是可能会导致不连续性

      不改变每个维度的大小，只改变维度的顺序；可能导致tensor在内存中不连续

     只修改存储元数据(例如：维度、步长等)，改变了数据的访问方式但是不创建副本

5. transpose

   视图操作，可能会导致不连续性

   只会交换两个维度；通常不复制数据，只创建新视图，改变了数据的访问方式但是不创建副本

   可能导致tensor在内存中不再连续

**关于梯度**

上述操作都是可微的，也就是说梯度可以通过这些操作反向传递，但是还是有一些细微差别：

**view和reshape**

1. 由于view和reshape创建的是原始数据的新视图，共享相同的内存
2. 在反向传播时，梯度会正确地映射回原始形状
3. 如果tensor连续，通常不会有问题
4. 如果原始tensor非连续，使用view可能会引发错误，或者使用view之前调用contiguous方法
5. 或者使用reshape，他会在需要的时候创建一个新的连续张量
6. 在复杂的view链中，在某些情况下可能导致内存泄漏

**permute和transpose**

1. 这些操作改变了tensor在内存中的布局顺序；反向传播时，梯度会根据这些变化正确地重新排列
2. 但是经过permute和transpose后tensor变得非连续，非连续的效率较低，可能会影响梯度计算的性能
3. 如果在permute和transpose后进行需要连续性的操作，系统会隐式调用contiguou()，会创建新的内存副本，增加内存
4. 频繁的transpose/permute会导致模型训练变慢

## 软选择(soft-selection) <-> 硬决策(hard selection)

根据某种概率或者权重，柔性地进行选择的方法；通常指模型对输入的连续、概率性分配，**可微**,支持标准梯度下降，支持反向传播，梯度下降

1. softmax

     $P(x_i) = \frac{e^{\beta x_i}}{\sum_j e^{\beta x_j}}$

     其中，$\beta$是温度参数，控制分布的平滑程度

      特点：

       * $\beta \to 0$时，所有选择几乎等概率，接近均匀分布

       * $\beta \to \infty$时，softmax变为近似硬选择(选择最大值)
2. Gumbel-softmax

     $y_i = \frac{exp((log(\pi_i)+g_i)/\tau)}{\sum_j exp((log(\pi_j)+g_j)/tau)}$

      其中 $\pi_i$是类别的原始权重，$g_i ~ Gumbel(0,1)$是Gumbel噪声，用于模拟离散采样，$\tau$是温度参数，控制离散程度

       特点：

         * 低温度$\tau \to 0$时，近似one-hot矢量(离散)

         * 高温度 $\tau \to \inify$时，接近均匀分布

         * 通过梯度传播优化，可以在离散任务中使用梯度下降
3. Top-k softmax
     



