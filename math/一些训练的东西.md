# 一些训练的东西

## MSE & RMSE

MES ： 均方误差

  $MSE = \frac{1}{n} \sum^n_{i=1}(y_i-\hat{y}_i)^2$

RMSE： 均方根误差

  $RMSE = \sqrt{\frac{1}{n}\sum^n_{i=1}(y_i-\hat{y}_i)^2}$

均方误差通常用于回归问题，预测的是连续的数值，需要衡量预测值与其真实值之间的距离或者误差

对于分类问题来说，通常使用：

  * acc
  * precision：在所有被预测为正类的样本中，真正为正类的比例

    $Precision = \frac{TP}{TP+FP}$
    
  * recall:在所有真实为正类的样本中，被正确预测为正类的比例
    
      $Recall = \frac{TP}{TP+FN}$
    
  * f1分数：精确率和召回率的调和平均数
    
      $F1 = 2\cdot \frac{Precision \cdot Recall}{Precision + Recall}$
    
* 对数损失 LogLoss:衡量概率预测的不确定性

  $LogLoss = - 1\frac{1}{N}\sum^N_{i=1}[y_ilog(p_i)+(1-y_i)log(1-p_i)]$

* 交叉熵损失，预测概率分布与真实分布之间的差异，多分类问题公式：

    $CrossEntropy = -\sum^N_{i=1}\sum^M_{j=1}y_{ij}log(p_{ij})$
  
关于为什么对数损失和交叉熵损失使用负数：

  在信息伦中，当一个事件的概率为 $p$时，该事件包含的信息量定义为 $-log(p)$，概率越小，信息量越大，即罕见事件发生时提供的信息更多

  在机器学习中，我们希望通过最大化模型对正确标签的预测概率，即最大化对数似然： $最大化 log(p(正确类别))$

  最小化损失函数：但是由于优化算法通常设计为最小化目标函数，所以我们取负值，将最大化问题转换为最小化问题，$最小化:-log(p(正确类别))$

  梯度特性：负对数函数在概率接近1时梯度接近0，在概率接近0时梯度非常大
  
  * 当模型对正确类别非常自信( $p \approx 1$)时，损失很小，梯度也很小

  * 当模型对正确类别完全不自信( $p \approx 0$)时，损失无限大，梯度也很小
  
  *TP*：实际为正，预测为正
  
  *TN*：实际为负，预测为负
  
  *FP*：实际为负，预测为正
  
  *FN*：实际为正，预测为负
